---
title: CPU
description: CPU
date: 2025-08-30
tags: [computer, cs]
series: CS
published: true
---

# 구성요소

- ALU(산술논리연산장치) : 연산을 수행하는 장치 (계산을 담당하는 회로)
- 제어 장치: 명령어를 해석하고 제어 신호를 내보내는 장치
- 레지스터(들): 명령어 처리 전후로 값을 임시 저장하는 장치

## 1. ALU

- 레지스터로부터 피연산자(연산의 대상)을 받아들이고
- 제어 장치로부터 제어 신호(연산할 작업)를 받아들인다.
- 연산의 결과를 레지스터, 플래그 레지스터에 저장한다.

  ![cpu](https://raw.githubusercontent.com/thdtjdgml415/next-blog/main/assets/img/cs/cpu/cpu.webp)

<aside>
📌 연산에 대한 부가정보가 필요할 때 플래그 레지스터에 담긴다.

</aside>

### 1.1 플래그 레지스터

연산의 결과에 대한 부가 정보가 담긴다. 예를 들어 **ALU**에서 계산한 값이 메모리에 담기려고 할 때 한정된 공간의 메모리의 값이 부족해 담기지 못한다(**오버플로우**). 이때 **플래그 레지스터**에 값이 추가적으로 담기게 된다.

- 부호 플래그 - 연산한 결과의 부호를 나타낸다.(연산결과가 음수인지 양수인지 모를 때 표시한다.)
- 제로 플래그 - 연산의 결과가 0 인지 여부를 나타낸다.
- 캐리 플래그 - 연산 결과 올림수나 빌림수가 발생했는지 여부를 나타낸다.
- 오버플로우 플래그 - 오버 플로우가 발생했는지 여부를 나타낸다.
- 인터럽트 플래그 - 인터업트가 가능한지 여부를 나타낸다. (**프로세스 실행 도중 예기치 않은 상황이 발생할 때 발생한 상황을 처리한 후 실행 중인 작업으로 복귀하는 것을 말한다**.)
- 슈퍼바이저 플래그 - 커널 모드로 실행 중인지, 사용자 모드로 실행 중인지를 나타낸다. (운영체제 파트)

<aside>
📌

커널 모드 - 특별하고 중요한 운영체제로 최적화를 위해 필요함 예를 들어 다른 프로제스에 들어갈 명령어를 커널 모드에서만 실행이 가능하다.

</aside>

## 2. 제어장치

- 제어 신호를 내보내고, 명령어를 해석하는 장치

제어장치가 명령어를 해석하고 제어신호를 내보낼때 **플래그 레지스터의 플래그**와 **명령어 레지스터의 명령어**를 받아들이게 된다.

받아들인 **신호는 다양한 구성요소로 전기신호를 내보낼 수 있다**. 예를 들어 **CPU에 내부에 레지스터나 ALU로 제어신호를 보내거나 메모리, 입출력장치와 연결된 제어 버스로 내보내게 된다.**

또한 추가로 **클럭 신호**를 제어장치는 받아드릴 수 있다.

### 2.1 클럭 신호

- 부품을 일사분란하게 움직일 수 있게 하는 **시간 단위**
- 부품이 움직이는 박자
- 클럭 신호가 빠르게 반복되면? 빠르게 수행
- 클럭 신호가 느리게 반복되면? 상대적으로 느리게 수행

<aside>
📌 매번 일정하게 반복되는 신호가 아닌 인위적으로 조절 할 수 있다.

</aside>

## 3. 레지스터

- 프로그램의 실행 전후로 값을 임시 저장하는작은 저장장치
- 레지스터에 어떤 값이 저장되는지만 관찰해도 프로그램의 가장 저수준의 흐름을 볼 수 있다.
- CPU마다 레지스터의 이름, 크기, 종류가 다양하다.
- 디버거를 통해 간접적으로 살펴볼 수 있다.

| 1. 프로그램 카운터(중요) | 다음으로 메모리에 가져올 명령어 주소 (메모리에 읽어들일 주소)         |
| ------------------------ | --------------------------------------------------------------------- |
| 2. 명령어 레지스터       | 해석할 명령어 (메모리에서 읽어들인 주소)                              |
| 3. 메모리 주소 레지스터  | 메모리의 주소 (읽어들일 주소 값, 주소버스)                            |
| 4. 메모리 버퍼 레지스터  | 메모리와 주고받을 명령어와 데이터 (데이터 버스)                       |
| 5. 플래그 레지스터       | 연산 결과에 대한 부가 정보 저장                                       |
| 6. 범용 레지스터         | 범용적으로 사용가능한 레지스터 (여러 개 존재)                         |
| 7. 스택 포인터           | 스택 주소 지정 방식에서 사용되는, ‘스택의 꼭대기’를 가리키는 레지스터 |
| 8. 베이스 레지스터       | 변위 주소 지정 방식에서 사용되는, ‘떨어진 거리’를 가리키는 레지스터   |

<aside>
📌 프로그램 카운터 - 일반적으로 1씩 중가되며 메모리의 프로그램이 순차적으로 증가된다.
  ex) 일반적이지 않은 상황 : 명령어 - jump 등의 실행 시, 인터럭트

</aside>

### 3.1 변위 주소 지정 방식

오퍼랜드 필드의 값을 변위 삼아, 특정 레지스터 값을 더해 유효 주소를 얻는 주소지정

![cpu](https://raw.githubusercontent.com/thdtjdgml415/next-blog/main/assets/img/cs/cpu/cpu-1.webp)

### 3.2 변위 주소 지정 방식 - 상대주소지정

오퍼랜드 + 프로그램 카운터 == 유효주소

### 3.3 변위주소 지정 방식 - 베이스 레지스터 주소지정

오퍼랜드 + 베이스 레지스터(기준 주소 )== 유효주소

이 방식은 기준 주소를 지정하고 기준부터 임의의 값까지 떨어져 있는 주소까지를 사용하기 위해 이 방식을 사용한다. 상대 주소 지정보다 좀 더 자유롭게 위치를 지정할 수 있다.

### 3.4 명령어 사이클과 인터럽트

CPU는 일정한 주기에 따라 메모리로 부터 클럭 신호에 맞춰서 가져온다. 이 일정한 주기를 **명령어 사이**클이라고 한다. 이 사이클을 가져오는 흐름을 끊는 특별한 상황이 **인터럽트**다.

### 3.5 CPU가 명령어를 순차적으로 처리하는 양상

- 메모리에서 명령어를 갖고오고 (인출 사이클)
- 가져온 명령어를 실행하고 (실행 사이클)
- …….

이 사이클을 반복한다.

하지만 모든 처리를 설명할 수 없다.

- 실제 연산에 사용될 데이터를 얻기 위해 한 번 더 메모리에 접근해야 할 경우가 있다.

즉, **간접 주소지정** 방식을 사용하게 되면 간접적으로 메모리에 접근하고 추가적으로 다시 접근해 실행한다.

이 때문에 **간접 사이클** 방식을 추가한다.

![cpu](https://raw.githubusercontent.com/thdtjdgml415/next-blog/main/assets/img/cs/cpu/cpu-2.webp)

### 3.6 인터럽트

- 인터럽트(interupt) : 방해하다, 중단시키다.
- CPU의 정상적인 실행 흐름을 방해하는 신호

ex) Exception, Fault 등등 생각보다 잘 발생함

- 동기 인터럽트 (예외, Exeption) - 주로 CPU에서 방생 명령어 처리 도중 비정상적인 상황
- 비동기 인터럽트 (하드웨어 인터럽트) - 주로 입출력장치에서 발생, 세탁기 완료 알림, 전자렌인지 조리 완료 알림과 같은 ‘알림’ 역할 수행

### 3.7 하드웨어 인터럽트 처리 순서

1. 입출력장치는 CPU에게 인터럽트 요청 신호를 보냄
2. CPU는 실행 사이클 이후 인출 전 인터럽트 여부 확인
3. CPU는 인터럽트 요청 확인 후, 인터럽트 플래그를 통해 인터럽트 수용 여부 확인
4. 인터럽트가 가능하다면 지금까지의 작업 백업 —> 스택에 백업
5. 인터럽트 벡터를 참고하여 \*인터럽트 서비스 루틴(인터럽트 핸들러 실행)
6. 인터럽트 서비스 루틴 실행 후 백업한 작업 복구, 실행 재개

<aside>
📌 인터럽트 서비스 루틴 - 해당 인터럽트를 처리하기 위한 특별한 프로그램 (여러개가 존재할 수 있음).           인터럽트 백터 - 인터럽트 서비스 루틴의 시작주소를 포함하는 인터럽트 서비스 루틴의 식별정보.               인터럽트 요청 신호 - CPU 작업을 방해하는 인터럽트에 대한 요청

</aside>

![cpu](https://raw.githubusercontent.com/thdtjdgml415/next-blog/main/assets/img/cs/cpu/cpu-3.webp)

![cpu](https://raw.githubusercontent.com/thdtjdgml415/next-blog/main/assets/img/cs/cpu/cpu-3-1.webp)

## 4. 멀티 코어와 멀티 프로세서

빠른 CPU를 위한 하드웨어적 설계

- 컴퓨터 부품은 클럭 신호에 맞춰 일사 분란하게 움직인다.
- CPU는 클럭 신호에 따라 명령어 사이클에 맞춰 명령어들을 실행한다.

<aside>
📌 클럭 신호가 빠르게 반복된다면? - 클록 속도가 높아지고 명령어도 빠르게 실행됨(Hz단위)

</aside>

- 클럭 속도가 높은 `CPU`는 일반적으로 성능이 좋다.
- 클럭 속도 `(Hz)`: 1초에 반된 클럭의 횟수로 측정

요즘은 `GHz`단위로 측정된다. `Hz * 10^9`

<aside>
📌 클럭 속도는 동적으로 동작하며 일정하지 않다.

</aside>

CPU 오버클럭킹

- 임의로 클럭 속도를 끌어올리는 기술
- 부팅시 BIOS에서 설정 가능

<aside>
📌 클럭 속도를 높이면 발열 문제가 심각해지기 때문에 수명이 줄어든다.

</aside>

### 4.1 코어와 멀티코어

클럭 수를 높이는 방법 이외에 성능을 높일 수 있는 방법은 **코어의 수를 늘리고 스레드 수를 늘리는 것!**

- 코어 명령어를 인출하고, 해석하고, 실행하는 CPU 내 부품
- 코어가 여러 개 있다면? 한 번에 여러 명령어 인출, 해석, 실행 가능
- 스레드 수를 늘리기 ⇒ 멀티스레드 프로세서(이는 하드웨어적 스레드를 이야기 하는 것)

<aside>
📌 명령어를 인출하고, 해석하고, 실행하는 건 CPU의 정의였다. 하지만 과거에는 하나의 코어만 존재했고 오늘날에는 여러개가 존재하기 때문에 코어의 정의로 변경되었다.

</aside>

<aside>
📌 하드웨어 스레드: 하나의 코어가 동시에 처리하는 명령어 단위                                                            소프트웨어 스레드: 하나의 프로그램을 독립적으로 실행하는 단위

</aside>

스레드는 하드웨어에서 사용되는 것과 소프트웨어에서 사용되는 스레드로 나눌 수 있는데 이는 혼용되기 쉽다.

하드웨어적 스레드는 하나의 코어가 동시에 처리하는 명령어 단위로, 1개의 스레드로도 나누어서 소프트웨어적 스레드를 여러개 구성할 수 있다. **즉, 메모리에서 프로그램이 몇개나 실행되고 있는지 판단할 수 있는 것이 소프트웨어 스레드이고, 하나의 코어가 명령어를 동시에 처리하는 단위를 말한다.**

그렇다면 CPU는 한 코어로 여러 명령어를 어떻게 실행이 가능할까?

<aside>
📌 복수의 레지스터 세트를 사용한다.(하나의 명령어를 실행하기 위해 꼭 필요한 레지스터 집합)

</aside>

즉, **위에서 설명한 레지스터 구성품들이 여러개 있다면 여러 명령어를 동시에 실행할 수 있을 것이다.**

![cpu](https://raw.githubusercontent.com/thdtjdgml415/next-blog/main/assets/img/cs/cpu/cpu-4.webp)

- 메모리 + 메모리에 저장된 프로그램 입장에서 하드웨어 스레드와 코어를 구분할 수 없다.
- 각 하드웨어를 마치 하나의 단일 스레드/ 코어 프로세서로 인식한다.
- 이런 점에서 하드웨어 스레드를 **논리 프로세서**라고 부르기도 한다.

비유해서 설명해 보자면 스타크래프트가 있다.

- 테란은 1개의 건물에 1개의 병력만 뽑을 수 있다. (1코어 1스레드)
- 저그는 1개의 해처리에 3마리의 크립을 이용해 3마리를 뽑아 낼 수 있다. (1코어 3스레드)

그렇다면 테란은 저그를 보고 6코어 6스레드라고 판단한다. (논리 프로세서)

## 5. 명령어 병렬 처리

명령어 병렬 처리 기법은 여러개가 존재하지만 핵심은 **파이프라이닝**이다. 즉, 마치 공장의 생성라인 처럼 여러개의 명령어를 여러개의 라인으로 동시에 처리하는 방법이다. 현대 CPU는 해당 기법을 가지고 처리한다. 이는 CPU의 성능과 밀접하게 관련되어있다.

### 5.1 명령어 파이프라이닝

하나의 명령어가 처리되는 과정을 비슷한 시간 간격으로 나누면

1. 명령어 인출
2. 명령어 해석
3. 명령어 실행
4. 명령어 저장

로 가정해보자.

**위 단계들은 서로 겹치지만 않는다면 한꺼번에 실행할 수 있다.**

![cpu](https://raw.githubusercontent.com/thdtjdgml415/next-blog/main/assets/img/cs/cpu/cpu-5.webp)

<aside>
📌 명령어가 공장 생상 라인 처럼 명령어가 처리되는 서로 다른 단계를 동시에 처리한다.

</aside>

### 5.2 파이프라인 위험

명령어 파이프라이닝에 실패하는 시나리오

1. 데이터 위험(cpu hazard)
2. 제어 위험(cpu hazard)
3. 구조적 위험(structure hazard)

### 데이터 위험

명령어 간 의존성에 의해 발생 → A라는 명령어가 저장이 되어야 B를 실행할 수 있을 때, 즉 관련되어 있다면 동시에 처리하지 못한다.

```jsx
// 1. 데이터가 쓰여진 직후 그 데이터를 읽어들이는 경우 (RAW)
명령1: R1 < -R2 + R3;
명령2: R4 < -R1 + R2;
// R1이 연관 되어 있기 때문에 병렬 처리할 수 없다.

// 2. 데이터를 쓴 직후 그 데이터에 새 내용을 쓰는 경우 (WAW)
명령1: R1 < -R2 + R3;
명령2: R1 < -R4 + R5;
// R1의 값이 덮어지기 떄문에 R1의 결과 값이 명령2가 나와야 하지만 동시에 처리하다가 명령1이 나올 수 있다.

// 3. 데이터를 읽어들인 직후 그 데이터에 새 내용을 쓰는 경우 (WAR)
명령1: R3 < -R2 + R1;
명령2: R1 < -R4 + R5;
// R1의 값에 따라 달라지기 때문이다.
```

### 제어 위험

프로그램 카운터의 갑작스러운 변화에 의해 발생 (분기)

인터럽트나 jump 명령어 등.. 사용이 되었을때 카운터가 변하기 때문에 병렬 처리되지 못한다.

이를 예측하고 예방하기 위해서 **분기 예측(brach prediction)**이라는 기술을 사용한다.

### 구조적 위험

서로 다른 명령어가 같은 자원을 사용 할 경우 발생 할 수도 있다.

하지만 하드웨어적 설계에 따라 다를 수 있다.

### 파이프라이닝의 발전: 슈퍼 스칼라

- 다수의 명령어 파이프라인을 두는 방식
- 여러 명령어 동시 인출 / 해석 / 실행 / 저장이 가능한 CPU

**파이프라인의 갯수에 비례해서 처리 속도가 늘어나진 않는다.**

- hazard가 더욱 까다로워짐
- 명령어의 의존도가 상승하기 때문

### 파이프라이닝을 십분 활용하기 위한 CPU 구조

- CISC: Complex Instruction Set Computer (Intel x86 CPU)
- RISC: Reduced Instruction Set Computer (ARM CPU)

### CISC

- 복잡하고 다양한 기능의 명령어 제공
- 다양한 주소 지정 방식 제공
- 적은 명령어 수로 명령어 실행 가능

소스코드를 컴파일 했을 때 명령어 수가 적어 **메모리 절약에 효과적임 하지만 오늘날에는 메모리가 커져 밀린다**

`CISC`는 하나의 명령어 실행에 일정하지 않은 클록 수 → 명령어 파이프라이닝에 불리함

- 대부분의 명령어는 사용되지 않는다.

<aside>
📌 CISC 명령어 중 20% 정도의 명령어가 전체 명령어의 80%를 차지

</aside>

### RISC

- 짧고 규격화된 명령어 → 명령어 파이프라이닝에 유리
- 적은 수의 명령어 제공
- 메모리 접근 최소화 (레지스터 활용) (load-store structure)
- CISC에 비해 더 많은 명령어로 실행 → 컴파일러의 역할이 중요

### 정리

![cpu](https://raw.githubusercontent.com/thdtjdgml415/next-blog/main/assets/img/cs/cpu/cpu-6.webp)

## 6. 비순차적 명령어 처리

OOOE(Out-of-Order-Execution)

**파이프라이닝 내의 의존 관계가 없는 명령어를 순차적으로 처리하지 않는 방법**

```bash
1. M(100) <- 1
2. M(101) <- 2
3. M(102) <- M(100) + M(101)
4. M(150) <- 1
5. M(151) <- 2
6. M(152) <- 3
```

위 명령어들은 파이프라이닝이 불가능하다.

왜냐하면 1번 ,2번 명령어와 3번 명령어는 의존관게가 성립하기 때문에 데이터 위험이 있다.

그렇다면 3번 명령어를 마지막에 실행한다면 전체적인 결과 값이 달라질까?

```bash
1. M(100) <- 1
2. M(101) <- 2
4. M(150) <- 1
5. M(151) <- 2
6. M(152) <- 3
3. M(102) <- M(100) + M(101)
```

**결과적으로 문제 없이 실행되고 값도 정상적으로 실행된다.**

이를 비순차적 명령어 처리라고 한다.

<aside>
📌 즉, 순서를 바꾸어 실행해도 **프로그램 실행에 영향이 없는 명령어 순서**를 바꿈으로써 파이프라이닝 성능을 높이는 기법을 **비순차적 명령어** 처리라 한다.

</aside>
